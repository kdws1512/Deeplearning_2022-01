{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "타이타닉 데이터 이진분류 정확도 경시대회.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 타이타닉 데이터 이진분류 정확도 경시대회\n",
        "\n",
        "    - Seaborn titanic data: 전처리는 ML에서 했던대로 할 것\n",
        "    - random seed = 2022\n",
        "    - train_test_split : test_size=0.2\n",
        "    - validation_split = 0.2\n",
        "신경망을 사용해서 정확도를 도출\n",
        "\n",
        "모델 정의/설정/실행 --> 임의로 결정\n",
        "\n",
        "\n",
        "파일이름: 이름0.8934html"
      ],
      "metadata": {
        "id": "rPFmJflDp0nC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dn8N_6uQpzkF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "seed = 2022\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = sns.load_dataset('titanic')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "XaplzzwwqECl",
        "outputId": "b395b50a-7f91-49a6-bfef-51cf1fba484b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-2d140f62-054f-4c09-bff1-09ae7605f8d7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>survived</th>\n",
              "      <th>pclass</th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>sibsp</th>\n",
              "      <th>parch</th>\n",
              "      <th>fare</th>\n",
              "      <th>embarked</th>\n",
              "      <th>class</th>\n",
              "      <th>who</th>\n",
              "      <th>adult_male</th>\n",
              "      <th>deck</th>\n",
              "      <th>embark_town</th>\n",
              "      <th>alive</th>\n",
              "      <th>alone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>S</td>\n",
              "      <td>Third</td>\n",
              "      <td>man</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>no</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C</td>\n",
              "      <td>First</td>\n",
              "      <td>woman</td>\n",
              "      <td>False</td>\n",
              "      <td>C</td>\n",
              "      <td>Cherbourg</td>\n",
              "      <td>yes</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>S</td>\n",
              "      <td>Third</td>\n",
              "      <td>woman</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>yes</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>S</td>\n",
              "      <td>First</td>\n",
              "      <td>woman</td>\n",
              "      <td>False</td>\n",
              "      <td>C</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>yes</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>S</td>\n",
              "      <td>Third</td>\n",
              "      <td>man</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>no</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2d140f62-054f-4c09-bff1-09ae7605f8d7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2d140f62-054f-4c09-bff1-09ae7605f8d7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2d140f62-054f-4c09-bff1-09ae7605f8d7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   survived  pclass     sex   age  ...  deck  embark_town  alive  alone\n",
              "0         0       3    male  22.0  ...   NaN  Southampton     no  False\n",
              "1         1       1  female  38.0  ...     C    Cherbourg    yes  False\n",
              "2         1       3  female  26.0  ...   NaN  Southampton    yes   True\n",
              "3         1       1  female  35.0  ...     C  Southampton    yes  False\n",
              "4         0       3    male  35.0  ...   NaN  Southampton     no   True\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked', 'deck']]\n",
        "df.head()"
      ],
      "metadata": {
        "id": "ysM_oQRiqQoU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "e84b0a1b-2228-47b2-e288-acfdbb44e611"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8337e286-9b7d-4887-9c19-b8518982b747\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>survived</th>\n",
              "      <th>pclass</th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>sibsp</th>\n",
              "      <th>parch</th>\n",
              "      <th>fare</th>\n",
              "      <th>embarked</th>\n",
              "      <th>deck</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>S</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>S</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>S</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>S</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8337e286-9b7d-4887-9c19-b8518982b747')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8337e286-9b7d-4887-9c19-b8518982b747 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8337e286-9b7d-4887-9c19-b8518982b747');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   survived  pclass     sex   age  sibsp  parch     fare embarked deck\n",
              "0         0       3    male  22.0      1      0   7.2500        S  NaN\n",
              "1         1       1  female  38.0      1      0  71.2833        C    C\n",
              "2         1       3  female  26.0      0      0   7.9250        S  NaN\n",
              "3         1       1  female  35.0      1      0  53.1000        S    C\n",
              "4         0       3    male  35.0      0      0   8.0500        S  NaN"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2E2_gFQcsX4n",
        "outputId": "d47e9f6e-0c31-48ec-dc4a-d3a18dc60a11"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "survived      0\n",
              "pclass        0\n",
              "sex           0\n",
              "age         177\n",
              "sibsp         0\n",
              "parch         0\n",
              "fare          0\n",
              "embarked      2\n",
              "deck        688\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.age.fillna(df.age.mean(), inplace=True)"
      ],
      "metadata": {
        "id": "KdfK9M6ZsYUD"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.age.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJmiEmrqscqQ",
        "outputId": "effdd20a-de54-4d58-d30d-436013593ceb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.embarked.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdIPnVmIse7r",
        "outputId": "ea59fb39-1871-46a3-81ee-13020e6226e3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "S    644\n",
              "C    168\n",
              "Q     77\n",
              "Name: embarked, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.embarked.fillna('S', inplace=True)\n",
        "df.embarked.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3Zk_0yZsgnZ",
        "outputId": "65cc7c1f-a5f8-43e3-e16d-9809e2b3ddac"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "round(df['age'].mean(), 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAFTP48lNKyV",
        "outputId": "691c0089-85d9-44ac-eeb0-ba33f237a97b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29.7"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['age'].fillna(round(df['age'].mean(), 1), inplace=True)\n",
        "df.head(6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "fpWW7AquNPIL",
        "outputId": "ab065fb1-99e9-45ed-9e44-599e453beb20"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-2f4e89df-e159-4cca-b130-1b0a0520d429\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>survived</th>\n",
              "      <th>pclass</th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>sibsp</th>\n",
              "      <th>parch</th>\n",
              "      <th>fare</th>\n",
              "      <th>embarked</th>\n",
              "      <th>deck</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>S</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>female</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>S</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>S</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>S</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>29.699118</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.4583</td>\n",
              "      <td>Q</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2f4e89df-e159-4cca-b130-1b0a0520d429')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2f4e89df-e159-4cca-b130-1b0a0520d429 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2f4e89df-e159-4cca-b130-1b0a0520d429');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   survived  pclass     sex        age  sibsp  parch     fare embarked deck\n",
              "0         0       3    male  22.000000      1      0   7.2500        S  NaN\n",
              "1         1       1  female  38.000000      1      0  71.2833        C    C\n",
              "2         1       3  female  26.000000      0      0   7.9250        S  NaN\n",
              "3         1       1  female  35.000000      1      0  53.1000        S    C\n",
              "4         0       3    male  35.000000      0      0   8.0500        S  NaN\n",
              "5         0       3    male  29.699118      0      0   8.4583        Q  NaN"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns=['deck'], inplace=True)\n",
        "df.isna().sum().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pw8dYqvRsj8d",
        "outputId": "6ab48dfe-c2ba-4b95-bbe7-85360e061cf6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()"
      ],
      "metadata": {
        "id": "r0Cq7PgOsly7"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.sex = le.fit_transform(df.sex)\n",
        "df.embarked = le.fit_transform(df.embarked)\n",
        "\n",
        "df.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "oYzCpx9Csoz1",
        "outputId": "5d8e6e72-0949-4fbe-b983-e3af47a12b17"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e0ea28a1-8e84-4cf9-ae6e-e9105720aafc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>survived</th>\n",
              "      <th>pclass</th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>sibsp</th>\n",
              "      <th>parch</th>\n",
              "      <th>fare</th>\n",
              "      <th>embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e0ea28a1-8e84-4cf9-ae6e-e9105720aafc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e0ea28a1-8e84-4cf9-ae6e-e9105720aafc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e0ea28a1-8e84-4cf9-ae6e-e9105720aafc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   survived  pclass  sex   age  sibsp  parch     fare  embarked\n",
              "0         0       3    1  22.0      1      0   7.2500         2\n",
              "1         1       1    0  38.0      1      0  71.2833         0\n",
              "2         1       3    0  26.0      0      0   7.9250         2"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(df.values[:,-1], return_counts=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glmKDduqsr91",
        "outputId": "e372f6d0-2622-4cef-96be-e2d26a423320"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0., 1., 2.]), array([168,  77, 646]))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.iloc[:,1:].values\n",
        "y = df.iloc[:,0].values"
      ],
      "metadata": {
        "id": "2fhYV850Nuzk"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X)\n",
        "X_std = scaler.transform(X)"
      ],
      "metadata": {
        "id": "i4dDEskEs0JX"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_std, y, stratify=y, random_state=seed, test_size=0.2\n",
        ")\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJJbUav4s2-0",
        "outputId": "36868dc8-2ada-4381-a319-9886e7edef86"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((712, 7), (179, 7), (712,), (179,))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "metadata": {
        "id": "C29gGT5dvIH4"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_titanic = Sequential([\n",
        "    Dense(61, input_dim=7, activation='relu'),\n",
        "    Dense(30, activation='relu'),\n",
        "    Dense(15, activation='relu'),\n",
        "    Dense(7, activation='relu'),\n",
        "    Dense(3, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "model_titanic.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4p0iscNtBlv",
        "outputId": "b7f15e6e-917c-4bb1-a447-a76567db51d4"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_31 (Dense)            (None, 61)                488       \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 30)                1860      \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 15)                465       \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 7)                 112       \n",
            "                                                                 \n",
            " dense_35 (Dense)            (None, 3)                 24        \n",
            "                                                                 \n",
            " dense_36 (Dense)            (None, 1)                 4         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,953\n",
            "Trainable params: 2,953\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_titanic.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "wRHKvLgHvExP"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "if not os.path.exists('titanic_model'):\n",
        "    os.mkdir('titanic_model')"
      ],
      "metadata": {
        "id": "CkmMxAJnvTCt"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_titanic_path = 'titanic_model/survive_titanic.h5'"
      ],
      "metadata": {
        "id": "7pEyMZN3vwFG"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "checkpoint = ModelCheckpoint(\n",
        "    model_titanic_path, monitor='val_loss', verbose=1, save_best_only=True\n",
        ")"
      ],
      "metadata": {
        "id": "_hSU2HUSv8BC"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping = EarlyStopping(patience=50)"
      ],
      "metadata": {
        "id": "Iyif6p7RxUeX"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist_titanic = model_titanic.fit(X_train, y_train, validation_split = 0.2, verbose=1,\n",
        "                                 epochs=200, batch_size=200,\n",
        "                                 callbacks=[checkpoint, early_stopping])\n",
        "model_titanic.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Izyi-OxpwHZZ",
        "outputId": "32bf89d3-8c32-4ec7-e555-469d07c832f9"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "1/3 [=========>....................] - ETA: 1s - loss: 0.6954 - accuracy: 0.5000\n",
            "Epoch 00001: val_loss improved from inf to 0.69191, saving model to titanic_model/survive_titanic.h5\n",
            "3/3 [==============================] - 1s 111ms/step - loss: 0.6941 - accuracy: 0.5571 - val_loss: 0.6919 - val_accuracy: 0.6014\n",
            "Epoch 2/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.6922 - accuracy: 0.6300\n",
            "Epoch 00002: val_loss improved from 0.69191 to 0.69030, saving model to titanic_model/survive_titanic.h5\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6919 - accuracy: 0.6221 - val_loss: 0.6903 - val_accuracy: 0.6014\n",
            "Epoch 3/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.6901 - accuracy: 0.6450\n",
            "Epoch 00003: val_loss improved from 0.69030 to 0.68860, saving model to titanic_model/survive_titanic.h5\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.6899 - accuracy: 0.6274 - val_loss: 0.6886 - val_accuracy: 0.6014\n",
            "Epoch 4/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.6878 - accuracy: 0.6550\n",
            "Epoch 00004: val_loss improved from 0.68860 to 0.68668, saving model to titanic_model/survive_titanic.h5\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.6878 - accuracy: 0.6221 - val_loss: 0.6867 - val_accuracy: 0.6014\n",
            "Epoch 5/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.6857 - accuracy: 0.6250\n",
            "Epoch 00005: val_loss improved from 0.68668 to 0.68455, saving model to titanic_model/survive_titanic.h5\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.6853 - accuracy: 0.6239 - val_loss: 0.6845 - val_accuracy: 0.6014\n",
            "Epoch 6/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.6839 - accuracy: 0.6050\n",
            "Epoch 00006: val_loss improved from 0.68455 to 0.68220, saving model to titanic_model/survive_titanic.h5\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.6825 - accuracy: 0.6239 - val_loss: 0.6822 - val_accuracy: 0.5944\n",
            "Epoch 7/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.6808 - accuracy: 0.6200\n",
            "Epoch 00007: val_loss improved from 0.68220 to 0.67974, saving model to titanic_model/survive_titanic.h5\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.6795 - accuracy: 0.6274 - val_loss: 0.6797 - val_accuracy: 0.5944\n",
            "Epoch 8/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.6779 - accuracy: 0.6150\n",
            "Epoch 00008: val_loss improved from 0.67974 to 0.67689, saving model to titanic_model/survive_titanic.h5\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6763 - accuracy: 0.6274 - val_loss: 0.6769 - val_accuracy: 0.5944\n",
            "Epoch 9/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.6748 - accuracy: 0.6250\n",
            "Epoch 00009: val_loss improved from 0.67689 to 0.67368, saving model to titanic_model/survive_titanic.h5\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6729 - accuracy: 0.6274 - val_loss: 0.6737 - val_accuracy: 0.5944\n",
            "Epoch 10/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.6692 - accuracy: 0.6300\n",
            "Epoch 00010: val_loss improved from 0.67368 to 0.67029, saving model to titanic_model/survive_titanic.h5\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.6687 - accuracy: 0.6292 - val_loss: 0.6703 - val_accuracy: 0.5944\n",
            "Epoch 11/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.6664 - accuracy: 0.6200\n",
            "Epoch 00011: val_loss improved from 0.67029 to 0.66635, saving model to titanic_model/survive_titanic.h5\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6642 - accuracy: 0.6292 - val_loss: 0.6663 - val_accuracy: 0.5944\n",
            "Epoch 12/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.6679 - accuracy: 0.6000\n",
            "Epoch 00012: val_loss improved from 0.66635 to 0.66169, saving model to titanic_model/survive_titanic.h5\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6590 - accuracy: 0.6309 - val_loss: 0.6617 - val_accuracy: 0.5874\n",
            "Epoch 13/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.6588 - accuracy: 0.6200\n",
            "Epoch 00013: val_loss improved from 0.66169 to 0.65610, saving model to titanic_model/survive_titanic.h5\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6533 - accuracy: 0.6309 - val_loss: 0.6561 - val_accuracy: 0.5874\n",
            "Epoch 14/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.6406 - accuracy: 0.6550\n",
            "Epoch 00014: val_loss improved from 0.65610 to 0.64976, saving model to titanic_model/survive_titanic.h5\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6469 - accuracy: 0.6292 - val_loss: 0.6498 - val_accuracy: 0.5874\n",
            "Epoch 15/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.6461 - accuracy: 0.5950\n",
            "Epoch 00015: val_loss improved from 0.64976 to 0.64242, saving model to titanic_model/survive_titanic.h5\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.6390 - accuracy: 0.6327 - val_loss: 0.6424 - val_accuracy: 0.5874\n",
            "Epoch 16/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.6327 - accuracy: 0.6400\n",
            "Epoch 00016: val_loss improved from 0.64242 to 0.63489, saving model to titanic_model/survive_titanic.h5\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.6303 - accuracy: 0.6344 - val_loss: 0.6349 - val_accuracy: 0.5874\n",
            "Epoch 17/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.6137 - accuracy: 0.6950\n",
            "Epoch 00017: val_loss improved from 0.63489 to 0.62553, saving model to titanic_model/survive_titanic.h5\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6197 - accuracy: 0.6467 - val_loss: 0.6255 - val_accuracy: 0.6014\n",
            "Epoch 18/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.6199 - accuracy: 0.6450\n",
            "Epoch 00018: val_loss improved from 0.62553 to 0.61311, saving model to titanic_model/survive_titanic.h5\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.6067 - accuracy: 0.6661 - val_loss: 0.6131 - val_accuracy: 0.6503\n",
            "Epoch 19/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.5930 - accuracy: 0.6800\n",
            "Epoch 00019: val_loss improved from 0.61311 to 0.59694, saving model to titanic_model/survive_titanic.h5\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.5918 - accuracy: 0.6837 - val_loss: 0.5969 - val_accuracy: 0.6923\n",
            "Epoch 20/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.5772 - accuracy: 0.6900\n",
            "Epoch 00020: val_loss improved from 0.59694 to 0.57760, saving model to titanic_model/survive_titanic.h5\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.5743 - accuracy: 0.7135 - val_loss: 0.5776 - val_accuracy: 0.7483\n",
            "Epoch 21/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.5509 - accuracy: 0.7500\n",
            "Epoch 00021: val_loss improved from 0.57760 to 0.55851, saving model to titanic_model/survive_titanic.h5\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.5532 - accuracy: 0.7663 - val_loss: 0.5585 - val_accuracy: 0.7552\n",
            "Epoch 22/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.5265 - accuracy: 0.8050\n",
            "Epoch 00022: val_loss improved from 0.55851 to 0.53949, saving model to titanic_model/survive_titanic.h5\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.5314 - accuracy: 0.8032 - val_loss: 0.5395 - val_accuracy: 0.7972\n",
            "Epoch 23/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.4947 - accuracy: 0.8400\n",
            "Epoch 00023: val_loss improved from 0.53949 to 0.52160, saving model to titanic_model/survive_titanic.h5\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.5079 - accuracy: 0.8120 - val_loss: 0.5216 - val_accuracy: 0.7832\n",
            "Epoch 24/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.4846 - accuracy: 0.8350\n",
            "Epoch 00024: val_loss improved from 0.52160 to 0.50656, saving model to titanic_model/survive_titanic.h5\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.4877 - accuracy: 0.8102 - val_loss: 0.5066 - val_accuracy: 0.7692\n",
            "Epoch 25/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.4698 - accuracy: 0.8200\n",
            "Epoch 00025: val_loss improved from 0.50656 to 0.49321, saving model to titanic_model/survive_titanic.h5\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.4706 - accuracy: 0.8120 - val_loss: 0.4932 - val_accuracy: 0.7832\n",
            "Epoch 26/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.4317 - accuracy: 0.8450\n",
            "Epoch 00026: val_loss improved from 0.49321 to 0.48266, saving model to titanic_model/survive_titanic.h5\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.4561 - accuracy: 0.8172 - val_loss: 0.4827 - val_accuracy: 0.7832\n",
            "Epoch 27/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.4168 - accuracy: 0.8500\n",
            "Epoch 00027: val_loss improved from 0.48266 to 0.47469, saving model to titanic_model/survive_titanic.h5\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.4452 - accuracy: 0.8207 - val_loss: 0.4747 - val_accuracy: 0.7832\n",
            "Epoch 28/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.4187 - accuracy: 0.8300\n",
            "Epoch 00028: val_loss improved from 0.47469 to 0.46874, saving model to titanic_model/survive_titanic.h5\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.4371 - accuracy: 0.8190 - val_loss: 0.4687 - val_accuracy: 0.7972\n",
            "Epoch 29/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.4216 - accuracy: 0.8200\n",
            "Epoch 00029: val_loss improved from 0.46874 to 0.46389, saving model to titanic_model/survive_titanic.h5\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.4308 - accuracy: 0.8278 - val_loss: 0.4639 - val_accuracy: 0.8042\n",
            "Epoch 30/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.4020 - accuracy: 0.8450\n",
            "Epoch 00030: val_loss improved from 0.46389 to 0.46182, saving model to titanic_model/survive_titanic.h5\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.4255 - accuracy: 0.8313 - val_loss: 0.4618 - val_accuracy: 0.8042\n",
            "Epoch 31/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3634 - accuracy: 0.8550\n",
            "Epoch 00031: val_loss improved from 0.46182 to 0.46044, saving model to titanic_model/survive_titanic.h5\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.4211 - accuracy: 0.8313 - val_loss: 0.4604 - val_accuracy: 0.8042\n",
            "Epoch 32/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3878 - accuracy: 0.8550\n",
            "Epoch 00032: val_loss improved from 0.46044 to 0.45911, saving model to titanic_model/survive_titanic.h5\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.4168 - accuracy: 0.8278 - val_loss: 0.4591 - val_accuracy: 0.8252\n",
            "Epoch 33/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.4139 - accuracy: 0.8200\n",
            "Epoch 00033: val_loss improved from 0.45911 to 0.45839, saving model to titanic_model/survive_titanic.h5\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.4135 - accuracy: 0.8295 - val_loss: 0.4584 - val_accuracy: 0.8322\n",
            "Epoch 34/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3832 - accuracy: 0.8500\n",
            "Epoch 00034: val_loss improved from 0.45839 to 0.45600, saving model to titanic_model/survive_titanic.h5\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.4099 - accuracy: 0.8330 - val_loss: 0.4560 - val_accuracy: 0.8252\n",
            "Epoch 35/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.4122 - accuracy: 0.8300\n",
            "Epoch 00035: val_loss improved from 0.45600 to 0.45567, saving model to titanic_model/survive_titanic.h5\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.4067 - accuracy: 0.8348 - val_loss: 0.4557 - val_accuracy: 0.8252\n",
            "Epoch 36/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3907 - accuracy: 0.8500\n",
            "Epoch 00036: val_loss improved from 0.45567 to 0.45467, saving model to titanic_model/survive_titanic.h5\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.4036 - accuracy: 0.8348 - val_loss: 0.4547 - val_accuracy: 0.8252\n",
            "Epoch 37/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3886 - accuracy: 0.8200\n",
            "Epoch 00037: val_loss improved from 0.45467 to 0.45301, saving model to titanic_model/survive_titanic.h5\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.4010 - accuracy: 0.8295 - val_loss: 0.4530 - val_accuracy: 0.8182\n",
            "Epoch 38/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.4737 - accuracy: 0.8050\n",
            "Epoch 00038: val_loss improved from 0.45301 to 0.45193, saving model to titanic_model/survive_titanic.h5\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.3989 - accuracy: 0.8366 - val_loss: 0.4519 - val_accuracy: 0.8182\n",
            "Epoch 39/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3600 - accuracy: 0.8600\n",
            "Epoch 00039: val_loss improved from 0.45193 to 0.44988, saving model to titanic_model/survive_titanic.h5\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.3966 - accuracy: 0.8348 - val_loss: 0.4499 - val_accuracy: 0.8252\n",
            "Epoch 40/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.4191 - accuracy: 0.8350\n",
            "Epoch 00040: val_loss improved from 0.44988 to 0.44947, saving model to titanic_model/survive_titanic.h5\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.3940 - accuracy: 0.8348 - val_loss: 0.4495 - val_accuracy: 0.8252\n",
            "Epoch 41/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.4068 - accuracy: 0.8200\n",
            "Epoch 00041: val_loss did not improve from 0.44947\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.3918 - accuracy: 0.8366 - val_loss: 0.4499 - val_accuracy: 0.8112\n",
            "Epoch 42/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.4127 - accuracy: 0.8400\n",
            "Epoch 00042: val_loss improved from 0.44947 to 0.44811, saving model to titanic_model/survive_titanic.h5\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.3906 - accuracy: 0.8383 - val_loss: 0.4481 - val_accuracy: 0.8182\n",
            "Epoch 43/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3940 - accuracy: 0.8250\n",
            "Epoch 00043: val_loss did not improve from 0.44811\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.3881 - accuracy: 0.8348 - val_loss: 0.4481 - val_accuracy: 0.8112\n",
            "Epoch 44/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3814 - accuracy: 0.8400\n",
            "Epoch 00044: val_loss improved from 0.44811 to 0.44644, saving model to titanic_model/survive_titanic.h5\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.3861 - accuracy: 0.8348 - val_loss: 0.4464 - val_accuracy: 0.8252\n",
            "Epoch 45/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3362 - accuracy: 0.8550\n",
            "Epoch 00045: val_loss improved from 0.44644 to 0.44439, saving model to titanic_model/survive_titanic.h5\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.3845 - accuracy: 0.8383 - val_loss: 0.4444 - val_accuracy: 0.8322\n",
            "Epoch 46/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.4098 - accuracy: 0.8150\n",
            "Epoch 00046: val_loss improved from 0.44439 to 0.44328, saving model to titanic_model/survive_titanic.h5\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.3829 - accuracy: 0.8366 - val_loss: 0.4433 - val_accuracy: 0.8392\n",
            "Epoch 47/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3277 - accuracy: 0.8550\n",
            "Epoch 00047: val_loss improved from 0.44328 to 0.44291, saving model to titanic_model/survive_titanic.h5\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.3814 - accuracy: 0.8383 - val_loss: 0.4429 - val_accuracy: 0.8392\n",
            "Epoch 48/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3910 - accuracy: 0.8400\n",
            "Epoch 00048: val_loss did not improve from 0.44291\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.3800 - accuracy: 0.8418 - val_loss: 0.4437 - val_accuracy: 0.8392\n",
            "Epoch 49/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3883 - accuracy: 0.8450\n",
            "Epoch 00049: val_loss did not improve from 0.44291\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.3784 - accuracy: 0.8418 - val_loss: 0.4453 - val_accuracy: 0.8182\n",
            "Epoch 50/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.4034 - accuracy: 0.8400\n",
            "Epoch 00050: val_loss did not improve from 0.44291\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.3768 - accuracy: 0.8436 - val_loss: 0.4438 - val_accuracy: 0.8252\n",
            "Epoch 51/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3845 - accuracy: 0.8450\n",
            "Epoch 00051: val_loss did not improve from 0.44291\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.3755 - accuracy: 0.8401 - val_loss: 0.4443 - val_accuracy: 0.8252\n",
            "Epoch 52/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3722 - accuracy: 0.8400\n",
            "Epoch 00052: val_loss did not improve from 0.44291\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.3743 - accuracy: 0.8436 - val_loss: 0.4443 - val_accuracy: 0.8252\n",
            "Epoch 53/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3897 - accuracy: 0.8300\n",
            "Epoch 00053: val_loss did not improve from 0.44291\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.3725 - accuracy: 0.8489 - val_loss: 0.4449 - val_accuracy: 0.8182\n",
            "Epoch 54/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3881 - accuracy: 0.8400\n",
            "Epoch 00054: val_loss did not improve from 0.44291\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.3715 - accuracy: 0.8471 - val_loss: 0.4459 - val_accuracy: 0.8042\n",
            "Epoch 55/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3207 - accuracy: 0.8700\n",
            "Epoch 00055: val_loss did not improve from 0.44291\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.3708 - accuracy: 0.8506 - val_loss: 0.4467 - val_accuracy: 0.8112\n",
            "Epoch 56/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3799 - accuracy: 0.8300\n",
            "Epoch 00056: val_loss did not improve from 0.44291\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.3696 - accuracy: 0.8453 - val_loss: 0.4449 - val_accuracy: 0.8252\n",
            "Epoch 57/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.4007 - accuracy: 0.8500\n",
            "Epoch 00057: val_loss did not improve from 0.44291\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.3684 - accuracy: 0.8489 - val_loss: 0.4456 - val_accuracy: 0.8252\n",
            "Epoch 58/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3797 - accuracy: 0.8350\n",
            "Epoch 00058: val_loss did not improve from 0.44291\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.3670 - accuracy: 0.8506 - val_loss: 0.4478 - val_accuracy: 0.8112\n",
            "Epoch 59/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3714 - accuracy: 0.8500\n",
            "Epoch 00059: val_loss did not improve from 0.44291\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.3659 - accuracy: 0.8489 - val_loss: 0.4477 - val_accuracy: 0.8252\n",
            "Epoch 60/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3896 - accuracy: 0.8450\n",
            "Epoch 00060: val_loss did not improve from 0.44291\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.3648 - accuracy: 0.8471 - val_loss: 0.4484 - val_accuracy: 0.8252\n",
            "Epoch 61/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3865 - accuracy: 0.8350\n",
            "Epoch 00061: val_loss did not improve from 0.44291\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.3641 - accuracy: 0.8471 - val_loss: 0.4474 - val_accuracy: 0.8182\n",
            "Epoch 62/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3663 - accuracy: 0.8500\n",
            "Epoch 00062: val_loss did not improve from 0.44291\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.3630 - accuracy: 0.8506 - val_loss: 0.4498 - val_accuracy: 0.8252\n",
            "Epoch 63/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3282 - accuracy: 0.8750\n",
            "Epoch 00063: val_loss did not improve from 0.44291\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.3622 - accuracy: 0.8541 - val_loss: 0.4488 - val_accuracy: 0.8182\n",
            "Epoch 64/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.4160 - accuracy: 0.8250\n",
            "Epoch 00064: val_loss did not improve from 0.44291\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.3604 - accuracy: 0.8541 - val_loss: 0.4465 - val_accuracy: 0.8252\n",
            "Epoch 65/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.2943 - accuracy: 0.8850\n",
            "Epoch 00065: val_loss did not improve from 0.44291\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.3597 - accuracy: 0.8506 - val_loss: 0.4469 - val_accuracy: 0.8252\n",
            "Epoch 66/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3857 - accuracy: 0.8250\n",
            "Epoch 00066: val_loss did not improve from 0.44291\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.3589 - accuracy: 0.8541 - val_loss: 0.4479 - val_accuracy: 0.8182\n",
            "Epoch 67/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3388 - accuracy: 0.8700\n",
            "Epoch 00067: val_loss did not improve from 0.44291\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.3583 - accuracy: 0.8541 - val_loss: 0.4511 - val_accuracy: 0.8182\n",
            "Epoch 68/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3594 - accuracy: 0.8550\n",
            "Epoch 00068: val_loss did not improve from 0.44291\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.3567 - accuracy: 0.8559 - val_loss: 0.4490 - val_accuracy: 0.8182\n",
            "Epoch 69/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3394 - accuracy: 0.8650\n",
            "Epoch 00069: val_loss did not improve from 0.44291\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.3560 - accuracy: 0.8541 - val_loss: 0.4478 - val_accuracy: 0.8182\n",
            "Epoch 70/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.4154 - accuracy: 0.8450\n",
            "Epoch 00070: val_loss did not improve from 0.44291\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.3547 - accuracy: 0.8612 - val_loss: 0.4465 - val_accuracy: 0.8252\n",
            "Epoch 71/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3521 - accuracy: 0.8800\n",
            "Epoch 00071: val_loss did not improve from 0.44291\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.3537 - accuracy: 0.8612 - val_loss: 0.4483 - val_accuracy: 0.8252\n",
            "Epoch 72/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3518 - accuracy: 0.8700\n",
            "Epoch 00072: val_loss did not improve from 0.44291\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.3525 - accuracy: 0.8594 - val_loss: 0.4506 - val_accuracy: 0.8042\n",
            "Epoch 73/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3510 - accuracy: 0.8650\n",
            "Epoch 00073: val_loss did not improve from 0.44291\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.3526 - accuracy: 0.8612 - val_loss: 0.4526 - val_accuracy: 0.8042\n",
            "Epoch 74/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3964 - accuracy: 0.8500\n",
            "Epoch 00074: val_loss did not improve from 0.44291\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.3507 - accuracy: 0.8629 - val_loss: 0.4525 - val_accuracy: 0.8042\n",
            "Epoch 75/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3747 - accuracy: 0.8450\n",
            "Epoch 00075: val_loss did not improve from 0.44291\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.3495 - accuracy: 0.8612 - val_loss: 0.4513 - val_accuracy: 0.8182\n",
            "Epoch 76/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3569 - accuracy: 0.8500\n",
            "Epoch 00076: val_loss did not improve from 0.44291\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.3481 - accuracy: 0.8594 - val_loss: 0.4515 - val_accuracy: 0.8182\n",
            "Epoch 77/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3237 - accuracy: 0.8900\n",
            "Epoch 00077: val_loss did not improve from 0.44291\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.3476 - accuracy: 0.8612 - val_loss: 0.4538 - val_accuracy: 0.8112\n",
            "Epoch 78/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3858 - accuracy: 0.8300\n",
            "Epoch 00078: val_loss did not improve from 0.44291\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.3465 - accuracy: 0.8594 - val_loss: 0.4562 - val_accuracy: 0.8042\n",
            "Epoch 79/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3298 - accuracy: 0.8600\n",
            "Epoch 00079: val_loss did not improve from 0.44291\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.3456 - accuracy: 0.8594 - val_loss: 0.4560 - val_accuracy: 0.8042\n",
            "Epoch 80/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3569 - accuracy: 0.8600\n",
            "Epoch 00080: val_loss did not improve from 0.44291\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.3446 - accuracy: 0.8629 - val_loss: 0.4539 - val_accuracy: 0.8182\n",
            "Epoch 81/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3257 - accuracy: 0.8750\n",
            "Epoch 00081: val_loss did not improve from 0.44291\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.3439 - accuracy: 0.8629 - val_loss: 0.4540 - val_accuracy: 0.8182\n",
            "Epoch 82/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3804 - accuracy: 0.8550\n",
            "Epoch 00082: val_loss did not improve from 0.44291\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.3430 - accuracy: 0.8629 - val_loss: 0.4561 - val_accuracy: 0.8042\n",
            "Epoch 83/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.2931 - accuracy: 0.8900\n",
            "Epoch 00083: val_loss did not improve from 0.44291\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.3434 - accuracy: 0.8612 - val_loss: 0.4592 - val_accuracy: 0.7972\n",
            "Epoch 84/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3619 - accuracy: 0.8300\n",
            "Epoch 00084: val_loss did not improve from 0.44291\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.3412 - accuracy: 0.8612 - val_loss: 0.4553 - val_accuracy: 0.8252\n",
            "Epoch 85/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3706 - accuracy: 0.8400\n",
            "Epoch 00085: val_loss did not improve from 0.44291\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.3407 - accuracy: 0.8629 - val_loss: 0.4555 - val_accuracy: 0.8182\n",
            "Epoch 86/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3655 - accuracy: 0.8450\n",
            "Epoch 00086: val_loss did not improve from 0.44291\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.3399 - accuracy: 0.8629 - val_loss: 0.4584 - val_accuracy: 0.8042\n",
            "Epoch 87/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3360 - accuracy: 0.8600\n",
            "Epoch 00087: val_loss did not improve from 0.44291\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.3382 - accuracy: 0.8629 - val_loss: 0.4607 - val_accuracy: 0.8042\n",
            "Epoch 88/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3255 - accuracy: 0.8650\n",
            "Epoch 00088: val_loss did not improve from 0.44291\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.3377 - accuracy: 0.8576 - val_loss: 0.4622 - val_accuracy: 0.8042\n",
            "Epoch 89/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3488 - accuracy: 0.8350\n",
            "Epoch 00089: val_loss did not improve from 0.44291\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.3376 - accuracy: 0.8612 - val_loss: 0.4600 - val_accuracy: 0.8112\n",
            "Epoch 90/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3089 - accuracy: 0.8800\n",
            "Epoch 00090: val_loss did not improve from 0.44291\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.3362 - accuracy: 0.8629 - val_loss: 0.4611 - val_accuracy: 0.8042\n",
            "Epoch 91/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3540 - accuracy: 0.8550\n",
            "Epoch 00091: val_loss did not improve from 0.44291\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.3351 - accuracy: 0.8594 - val_loss: 0.4625 - val_accuracy: 0.8042\n",
            "Epoch 92/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3342 - accuracy: 0.8600\n",
            "Epoch 00092: val_loss did not improve from 0.44291\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.3345 - accuracy: 0.8612 - val_loss: 0.4605 - val_accuracy: 0.8042\n",
            "Epoch 93/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3754 - accuracy: 0.8500\n",
            "Epoch 00093: val_loss did not improve from 0.44291\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.3336 - accuracy: 0.8612 - val_loss: 0.4607 - val_accuracy: 0.8042\n",
            "Epoch 94/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3292 - accuracy: 0.8700\n",
            "Epoch 00094: val_loss did not improve from 0.44291\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.3325 - accuracy: 0.8629 - val_loss: 0.4646 - val_accuracy: 0.8042\n",
            "Epoch 95/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3612 - accuracy: 0.8300\n",
            "Epoch 00095: val_loss did not improve from 0.44291\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.3321 - accuracy: 0.8576 - val_loss: 0.4631 - val_accuracy: 0.8042\n",
            "Epoch 96/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3079 - accuracy: 0.8800\n",
            "Epoch 00096: val_loss did not improve from 0.44291\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.3313 - accuracy: 0.8594 - val_loss: 0.4630 - val_accuracy: 0.8042\n",
            "Epoch 97/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3358 - accuracy: 0.8600\n",
            "Epoch 00097: val_loss did not improve from 0.44291\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.3301 - accuracy: 0.8629 - val_loss: 0.4665 - val_accuracy: 0.8042\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.4030 - accuracy: 0.8436\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.40300965309143066, 0.8435754179954529]"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del model_titanic"
      ],
      "metadata": {
        "id": "ivodcoIA0LwJ"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_titanic.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3P-Mcjhz0gk6",
        "outputId": "d1238c3c-25f9-4746-c00e-f72d0e84fd90"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 2ms/step - loss: 0.4030 - accuracy: 0.8436\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.40300965309143066, 0.8435754179954529]"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_acc = hist_titanic.history['accuracy']\n",
        "y_vloss = hist_titanic.history['val_loss']\n",
        "xs = np.arange(1,len(y_acc)+1)"
      ],
      "metadata": {
        "id": "ghv99e9tBLpR"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.plot(xs, y_acc, ms=5, label='train accuracy')\n",
        "plt.plot(xs, y_vloss, ms=5, label='validation loss')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.xlabel('Epoch')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "eM4qJQ1EDNwK",
        "outputId": "e30f2219-dec1-41be-e7aa-c1056cd70c7d"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}